{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b5928f",
   "metadata": {},
   "source": [
    "# Improvement Carvana_local_learning_prod_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca4aaf",
   "metadata": {},
   "source": [
    "## Подключение библиотек и загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Улучшения: \n",
    "# Убрал .cuda() из класса модели и добавил в даталоадеры перенос на gpu\n",
    "# Добавил трэйсинг моделии и ее сохранение, загрузку модели\n",
    "# Заменил лишний ресайз масок на передачу оригинолов масок\n",
    "# Сделал предсказания с разным размером батча\n",
    "# Нейтрализовал проявления хардкода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eadeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Написать комментарии и пояснения\n",
    "# Реализовать аугментацию\n",
    "# Разобраться как лучше интерполировать или ресайзить и как лучше интерполировать\n",
    "# Сделать submission при обучении на всем трерировочном датасете\n",
    "# Нужна ли стандартизация вместо нормализации\n",
    "# Попробовать softdice loss + bce (как в dlcource.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15971ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f662c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6386d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнять, если датасет не загружен\n",
    "!pip install -q kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!cp ~/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c carvana-image-masking-challenge\n",
    "!unzip ~/carvana-image-masking-challenge.zip ~/carvana_dataset/\n",
    "\n",
    "!unzip ~/carvana_dataset/train.zip -d ~/carvana_dataset/train\n",
    "!unzip ~/carvana_dataset/test.zip -d ~/carvana_dataset/test\n",
    "!unzip ~/carvana_dataset/train_masks.zip -d ~/carvana_dataset/train_masks\n",
    "\n",
    "!unzip ~/carvana_dataset/train_hq.zip -d ~/carvana_dataset/train_hq\n",
    "!unzip ~/carvana_dataset/test_hq.zip -d ~/carvana_dataset/test_hq\n",
    "\n",
    "!unzip ~/carvana_dataset/train_masks.csv.zip  ~/carvana_dataset/\n",
    "!unzip ~/carvana_dataset/sample_submission.csv.zip  ~/carvana_dataset/\n",
    "!unzip ~/carvana_dataset/metadata.csv.zip  ~/carvana_dataset/\n",
    "\n",
    "!rm ~/carvana-image-masking-challenge.zip\n",
    "!rm ~/carvana_dataset/test.zip\n",
    "!rm ~/carvana_dataset/train_masks.zip\n",
    "!rm ~/carvana_dataset/train.zip\n",
    "!rm ~/carvana_dataset/test_hq.zip\n",
    "!rm ~/carvana_dataset/train_hq.zip\n",
    "!rm ~/carvana_dataset/train_masks.csv.zip\n",
    "!rm ~/carvana_dataset/sample_submission.csv.zip\n",
    "!rm ~/carvana_dataset/metadata.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8be7cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3608d7",
   "metadata": {},
   "source": [
    "## Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec78c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_csv(imgs_path: str = None, masks_path: str = None) -> pd.DataFrame:\n",
    "    '''Функция получает на вход пути к директориям с изображениями и масками\n",
    "    и генерирует датафрейм, содержащий имя изображений, их адреса и адреса\n",
    "    соответствующих им масок\n",
    "  \n",
    "    Входные параметры:\n",
    "    imgs_path: str - путь к директории с изображениями,\n",
    "    masks_path: str - путь к директории с масками\n",
    "    Выходные параметры:\n",
    "    pd.DataFrame: data - dataframe, содержащий адреса изображений и соответствующих им масок'''\n",
    "\n",
    "    assert (imgs_path != None) & (masks_path != None)\n",
    "    # imgs_path or masks_path is equal None\n",
    "\n",
    "    data_img = {}\n",
    "    data_mask = {}\n",
    "    data_img['imgs_path'] = []\n",
    "    data_mask['masks_path'] = []\n",
    "    data_img['imgs_path'] = list(glob.glob(imgs_path + \"/*\"))\n",
    "    data_mask['masks_path'] = list(glob.glob(masks_path + \"/*\"))\n",
    "\n",
    "    data_img = pd.DataFrame(data_img)\n",
    "    data_mask = pd.DataFrame(data_mask)\n",
    "\n",
    "    def file_name(x):\n",
    "        return x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    data_img[\"file_name\"] = data_img[\"imgs_path\"].apply(lambda x: file_name(x))\n",
    "    data_mask[\"file_name\"] = data_mask[\"masks_path\"].apply(lambda x: file_name(x)[:-5])\n",
    "\n",
    "    data = pd.merge(data_img, data_mask, on = \"file_name\", how = \"inner\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5613d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(source_df: pd.DataFrame, separate_feature: str = None, test_size: float = 0.25) -> pd.DataFrame:\n",
    "    '''Функция разделяет source_df на две части с коэффициентом test_size\n",
    "    по уникальным значениям separate_feature так, чтобы в новых датафреймах\n",
    "    не было строк с одинаковыми значенияти из separate_feature\n",
    "\n",
    "    Входные параметры:\n",
    "    source_df: pd.DataFrame - датафрейм для разделения на train и test\n",
    "    separate_feature: str - поле, по которому датафрейм будет разделен\n",
    "    test_size: float - коэффициент разделения дтафрейма\n",
    "    Выходные параметры:\n",
    "    pd.DataFrame: data_train - датафрейм для тренировки\n",
    "    pd.DataFrame: data_valid - датафрейм для валидации'''\n",
    "  \n",
    "    if (separate_feature != None) & (separate_feature in source_df.columns):\n",
    "        train_cars, valid_cars = train_test_split(source_df[separate_feature].unique(), test_size=test_size, random_state=42)\n",
    "        data_valid = source_df[np.isin(source_df[separate_feature].values, valid_cars)]\n",
    "        data_train = source_df[np.isin(source_df[separate_feature].values, train_cars)]\n",
    "        assert data.shape[0] == (data_valid.shape[0] + data_train.shape[0])\n",
    "        assert np.isin(data_train[separate_feature].values, data_valid[separate_feature].values).sum() == 0\n",
    "    else:\n",
    "        data_train, data_valid = train_test_split(source_df, test_size=test_size)\n",
    "\n",
    "    return data_train, data_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712baa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICE(logits: torch.Tensor, targets: torch.Tensor, treashold: float) -> float:\n",
    "    '''Функция для вычисления DICE коэффициента для набора изображенй в формате torch.Tensor\n",
    "    Входные параметры:\n",
    "    logits: torch.Tensor - тензор из предсказанных масок в logit масштабе\n",
    "    targets: torch.Tensor - тензор из целевых целевых значений масок\n",
    "    treashold: float - порог для определения класса точки в предсказанной точке\n",
    "    Выходные параметры:\n",
    "    score: float - значение DICE коэффициента для набора предсказанных масок'''\n",
    "    \n",
    "    smooth = 1\n",
    "    num = targets.size(0)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    outputs = torch.where(probs > treashold, 1, 0)\n",
    "    m1 = outputs.view(num, -1)\n",
    "    m2 = targets.view(num, -1)\n",
    "    intersection = (m1 * m2)\n",
    "\n",
    "    score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "    score = score.sum() / num\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd108c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_rle(tensor: torch.Tensor) -> str:\n",
    "    '''Функция принимает одну маску в тензорном формате, элементы которой\n",
    "    имеют значения 0. и 1. и генерирует rle представление маски в строковом формате\n",
    "    Входные параметры:\n",
    "    tensor: torch.Tensor - маска в тензорном формате\n",
    "    Выходные параметры:\n",
    "    rle_str: str - rle представление маски в строком виде'''\n",
    "    \n",
    "    # Для правильной работы алгоритма необходимо, чтобы первое и последнее значения выпрямленной маски\n",
    "    # (что соответствует двум углам изображения) были равны 0. Это не должно повлиять на качество работы\n",
    "    # алгоритма, так как мы не ожидаем наличие объекта в этих точках (но даже если он там будет, качество\n",
    "    # не сильно упадет)\n",
    "    tensor = tensor.view(1, -1)\n",
    "    tensor = tensor.squeeze(0)\n",
    "    tensor[0] = 0\n",
    "    tensor[-1] = 0\n",
    "    rle = torch.where(tensor[1:] != tensor[:-1])[0] + 2\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    rle = rle.cpu().detach().numpy()\n",
    "    rle_str = rle_to_string(rle)\n",
    "    return rle_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dba4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_rle(mask_image: np.ndarray) -> str:\n",
    "    '''Функция принимает одну маску в формате массива numpy, элементы которой\n",
    "    имеют значения 0. и 1. и генерирует rle представление маски в строковом формате\n",
    "    Входные параметры:\n",
    "    mask_image: numpy.ndarray - маска в тензорном формате\n",
    "    Выходные параметры:\n",
    "    rle_str: str - rle представление маски в строком виде'''\n",
    "    \n",
    "    # Для правильной работы алгоритма необходимо, чтобы первое и последнее значения выпрямленной маски\n",
    "    # (что соответствует двум углам изображения) были равны 0. Это не должно повлиять на качество работы\n",
    "    # алгоритма, так как мы не ожидаем наличие объекта в этих точках (но даже если он там будет, качество\n",
    "    # не сильно упадет)\n",
    "    pixels = mask_image.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    rle_str = rle_to_string(runs)\n",
    "    return rle_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf01f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_string(runs: torch.Tensor) -> str:\n",
    "    '''Функция преобразует последовательноть чисел в тензоре runs\n",
    "    в строковое представление этой последовательности\n",
    "    Входные параметры:\n",
    "    runs: torch.Tensor - последовательность чисел в тензорном формате\n",
    "    Выходные параметры:\n",
    "    rle_str: str - строковое представление последовательности чисел'''\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd732aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rle(mask_addr: str) -> str:\n",
    "    '''Функция преобразует маску, имеющую адрес mask_addr и сохраненную в\n",
    "    формате .gif, элементы которой имеют значения 0 и 1 в rle представление\n",
    "    в строковом виде'''\n",
    "    \n",
    "    mask = Image.open(mask_addr).convert('LA') # преобразование в серый\n",
    "    mask = np.asarray(mask).astype('float')[:,:,0]\n",
    "    mask = mask/255.0\n",
    "    mask_rle = numpy_to_rle(mask)\n",
    "    return mask_rle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1dd14a",
   "metadata": {},
   "source": [
    "## Используемые классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b539ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceMetric(nn.Module):\n",
    "    def __init__(self, treashold=0.5):\n",
    "        super(DiceMetric, self).__init__()\n",
    "        self.treashold = treashold\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        with torch.no_grad():\n",
    "            smooth = 1\n",
    "            num = targets.size(0)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            outputs = torch.where(probs > self.treashold, 1, 0)\n",
    "            m1 = outputs.view(num, -1)\n",
    "            m2 = targets.view(num, -1)\n",
    "            intersection = (m1 * m2)\n",
    "\n",
    "            score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "            score = score.sum() / num\n",
    "            return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e9aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth = 1\n",
    "        num = targets.size(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4045a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetForTrain(Dataset):\n",
    "    def __init__(self, data_info, device, out_shape=(512, 512), skip_mask=False):\n",
    "        # Подаем наш подготовленный датафрейм\n",
    "        self.data_info = data_info\n",
    "        # Разделяем датафрейм на rgb картинки \n",
    "        self.image_arr = self.data_info.iloc[:,0]\n",
    "        # и на сегментированные картинки\n",
    "        self.mask_arr = self.data_info.iloc[:,2]\n",
    "        # Количество пар картинка-сегментация\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        # Устройство, на котором будут находиться выходные тензоры\n",
    "        self.device = device\n",
    "        # Пространственные размеры тензоров на выходе объекта даталоадера\n",
    "        self.out_shape = out_shape\n",
    "        # Нужно ли пробрасывать маску изображения на выход без изменений\n",
    "        self.skip_mask = skip_mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(self.image_arr[index])).astype('float')\n",
    "        img = (torch.as_tensor(img)/255.0).to(self.device)\n",
    "        # unsqueeze - чтобы interpolate работало\n",
    "        # permute - переставляем измерение каналов на 2-е место\n",
    "        img = img.unsqueeze(0).permute(0,3,1,2)\n",
    "        # clamp не позволяет выйти за границы значений\n",
    "        img = F.interpolate(input=img, size=self.out_shape, align_corners=False, mode='bicubic').clamp(min=0, max=1)\n",
    "        img = img.squeeze(0)\n",
    "        # Маски - одноканальные изображения со значениями 0 и 1\n",
    "        mask = Image.open(self.mask_arr[index])\n",
    "        mask = np.asarray(mask).astype('float')\n",
    "        # unsqueeze - добавляем измерение каналов\n",
    "        mask = (torch.as_tensor(mask)).to(self.device).unsqueeze(0) \n",
    "        # unsqueeze - чтобы interpolate работало\n",
    "        mask_small = mask.unsqueeze(0)\n",
    "        mask_small = F.interpolate(input=mask_small, size=self.out_shape, mode='nearest')\n",
    "        mask_small = mask_small.squeeze(0)\n",
    "        \n",
    "        # Если необходима исходная маска, то дополнительно возвращаем ее\n",
    "        if self.skip_mask == True:\n",
    "            return (img.float(), mask_small.float(), mask.float())\n",
    "        else:\n",
    "            return (img.float(), mask_small.float())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15588a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetForTest(Dataset):\n",
    "    def __init__(self, data_info, out_shape=(512, 512)):\n",
    "        # Подаем наш подготовленный датафрейм\n",
    "        self.data_info = data_info\n",
    "        \n",
    "        # Получаем адреса RGB изображений \n",
    "        self.image_addresses = self.data_info.iloc[:,0]\n",
    "        \n",
    "        # Количество пар картинка-сегментация\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        \n",
    "        self.out_shape = out_shape\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(self.image_addresses[index])).astype('float')\n",
    "        img = torch.as_tensor(img)/255    \n",
    "        # unsqueeze - чтобы interpolate работало\n",
    "        # permute - переставляем измерение каналов на 2-е место\n",
    "        img = img.unsqueeze(0).permute(0,3,1,2)\n",
    "        # clamp не позволяет выйти за границы значений\n",
    "        img = F.interpolate(input=img, size=self.out_shape, align_corners=False, mode='bicubic').clamp(min=0, max=1)\n",
    "        img = img.squeeze(0)\n",
    "        \n",
    "        image_address = self.image_addresses[index]\n",
    "        image_name = image_address.split('/')[-1]\n",
    "    \n",
    "        return (index, img.float(), image_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0a9bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробовать разные типы интерполяции\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def tensor_to_rle(tensor):\n",
    "        # We avoid issues with '1' at the start or end (at the corners of \n",
    "        # the original image) by setting those pixels to '0' explicitly.\n",
    "        # We do not expect these to be non-zero for an accurate mask, \n",
    "        # so this should not harm the score.\n",
    "        with torch.no_grad():\n",
    "            tensor = tensor.view(1, -1)\n",
    "            tensor = tensor.squeeze(0)\n",
    "            tensor[0] = 0\n",
    "            tensor[-1] = 0\n",
    "            rle = torch.where(tensor[1:] != tensor[:-1])[0] + 2\n",
    "            rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "            rle = rle.cpu().detach().numpy()\n",
    "            rle_str = rle_to_string(rle)\n",
    "            return rle_str\n",
    "    \n",
    "    @staticmethod\n",
    "    def rle_to_string(runs):\n",
    "        return ' '.join(str(x) for x in runs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, criterion, metric, optimizer, train_data_loader, valid_data_loader=None, epochs=1):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        # запускаем главный тренировочный цикл\n",
    "        epoch_train_losses = []\n",
    "        epoch_valid_losses = []\n",
    "        epoch_valid_metrics = []\n",
    "        result = {}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            time1 = time.time()\n",
    "            running_loss =0.0\n",
    "            train_losses = []\n",
    "            for batch_idx, (data, labels) in enumerate(train_data_loader):\n",
    "                data, labels = Variable(data), Variable(labels)        \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                train_losses.append(loss.item())\n",
    "                if (batch_idx+1) % 300 == 299:\n",
    "                    print(f'Train Epoch: {epoch+1}, Loss: {running_loss/300}')\n",
    "                    time2 = time.time()\n",
    "                    print(f'Spend time for 300 batches: {time2-time1} sec')\n",
    "                    time1 = time.time()\n",
    "                    running_loss = 0.0\n",
    "\n",
    "            train_loss = np.mean(train_losses)        \n",
    "            \n",
    "            \n",
    "            if valid_data_loader != None:\n",
    "                self.model.eval()\n",
    "                valid_metrics = []\n",
    "                valid_losses = []\n",
    "                for batch_idx, (data, labels_small, labels) in enumerate(valid_data_loader):\n",
    "                    data, labels, labels_small = Variable(data), Variable(labels), Variable(labels_small)\n",
    "                    outputs = self.model(data)\n",
    "                    # loss вычисляется для сжатых масок для правильной валидации (обучались на сжатых)\n",
    "                    # чтобы вовремя определить переобучение\n",
    "                    loss = criterion(outputs, labels_small)\n",
    "                    valid_losses.append(loss.item())\n",
    "                    #Преобразуем выход модели к размеру соответствующей маски\n",
    "                    outputs = F.interpolate(input=outputs, size=(labels.shape[2], labels.shape[3]), mode='nearest')\n",
    "\n",
    "                    # метрика считается для исходных размеров потому что именно так итоговое качество\n",
    "                    # определяется алгоритмом kaggle \n",
    "                    metric_value = metric(outputs, labels)\n",
    "                    valid_metrics.append(metric_value.item())\n",
    "                    \n",
    "                valid_loss    = np.mean(valid_losses)\n",
    "                valid_metric  = np.mean(valid_metrics)\n",
    "                print(f'Epoch {epoch+1}, train loss: {train_loss}, valid_loss: {valid_loss}, valid_metric: {valid_metric}')\n",
    "            else:\n",
    "                print(f'Epoch {epoch+1}, train loss: {train_loss}')\n",
    "                valid_loss = None\n",
    "                valid_metric = None\n",
    "            \n",
    "            epoch_train_losses.append(train_loss)\n",
    "            epoch_valid_losses.append(valid_loss)\n",
    "            epoch_valid_metrics.append(valid_metric)\n",
    "        \n",
    "        result['epoch_train_losses'] = epoch_train_losses\n",
    "        result['epoch_valid_losses'] = epoch_valid_losses\n",
    "        result['epoch_valid_metrics'] = epoch_valid_metrics\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, test_data_loader, predict_directory, output_size=(1280, 1918), \n",
    "                                                           mask_treashold=0.5, generate_rle_dataframe=True):\n",
    "        self.model.eval()\n",
    "        img_names = []\n",
    "        img_rles = []\n",
    "        \n",
    "        for batch_idx, (index, img, img_name)  in enumerate(test_data_loader):\n",
    "\n",
    "            img = Variable(img)        \n",
    "            img = img.cuda()\n",
    "            pred_mask_logit = self.model(img)\n",
    "            pred_mask_logit = F.interpolate(input=pred_mask_logit, size=output_size, mode='nearest')\n",
    "            pred_mask_logit_prob = torch.sigmoid(pred_mask_logit)\n",
    "            pred_mask = torch.where(pred_mask_logit_prob > mask_treashold, 1, 0)\n",
    "            #pred_mask = pred_mask.squeeze(0)\n",
    "            \n",
    "            # Каждое изображение в тензоре преобразуем в картинку и сохраняем\n",
    "            for i in range(pred_mask.shape[0]):\n",
    "                mask = (pred_mask[i].cpu().numpy() * 255.0)[0] # [0] - избавляемся от батч размерности\n",
    "                PIL_image = Image.fromarray(mask.astype('uint8'), 'L')\n",
    "                PIL_image.save((predict_directory+img_name[i]).split('.')[0]+'.gif')\n",
    "                \n",
    "                # Если требуется, получаем значения rle для каждой картинки\n",
    "                if generate_rle_dataframe == True:\n",
    "                    img_names.append(img_name[i])\n",
    "                    img_rles.append(tensor_to_rle(pred_mask[i]))\n",
    "                \n",
    "        if generate_rle_dataframe == True:\n",
    "            rle_dataframe = pd.DataFrame(list(zip(img_names, img_rles)), columns =['img_name', 'img_rle'])\n",
    "            return rle_dataframe\n",
    "    \n",
    "    def save(self, path_to_save='./model.pth'):\n",
    "        torch.save(self.model.state_dict(), path_to_save)\n",
    "    \n",
    "    def trace_save(self, path_to_save='./model.pth'):\n",
    "        example_forward_input = torch.rand(1, 3, 512, 512).to('cpu')\n",
    "        if next(self.model.parameters()).is_cuda:\n",
    "            example_forward_input= example_forward_input.to('cuda:0')\n",
    "            \n",
    "        traced_model = torch.jit.trace(self.model, example_forward_input)\n",
    "        torch.jit.save(traced_model, 'model.pt')\n",
    "    \n",
    "    def load(self, path_to_model='./model.pth'):\n",
    "        self.model.load_state_dict(torch.load(path_to_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e07ce",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21937687",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/dima/carvana_dataset'\n",
    "imgs_path  = dataset_path + '/train/train'\n",
    "masks_path = dataset_path + '/train_masks/train_masks'\n",
    "\n",
    "nn_image_shape = (512, 512)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "mask_treashold = 0.5\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d28b75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_csv(imgs_path=imgs_path, masks_path=masks_path)\n",
    "    \n",
    "# Добавляем признак, по которому будем разбивать датасет на train и test,\n",
    "# чтобы не было разных фотографий одной и той же машины в двух датасетах\n",
    "data[\"car\"] = data[\"file_name\"].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e54a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение с валидацией\n",
    "train_df, valid_df = get_train_test(data, separate_feature='car', test_size=0.25)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "valid_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train_data = CustomDatasetForTrain(train_df, device, out_shape=nn_image_shape)\n",
    "valid_data = CustomDatasetForTrain(valid_df, device, out_shape=nn_image_shape, skip_mask=True)\n",
    "\n",
    "train_data_loader = DataLoader(train_data,batch_size=4,shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_data,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94c06a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение без валидации\n",
    "train_data = CustomDatasetForTrain(data, device, out_shape=nn_image_shape)\n",
    "train_data_loader = DataLoader(train_data,batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca4b1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель на основе предложенной архитектуры\n",
    "model = smp.Unet('mobilenet_v2', classes=1, encoder_depth=5, \n",
    "                 encoder_weights='imagenet', decoder_channels = [256, 128, 64, 32, 16]).to(device)\n",
    "\n",
    "#model = smp.Unet('mobilenet_v2', classes=1, encoder_depth=5, \n",
    "#                 encoder_weights='imagenet').to(device)\n",
    "\n",
    "my_model = NeuralNetwork(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fb86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SoftDiceLoss()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=learning_rate)\n",
    "metric = DiceMetric(treashold=mask_treashold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca111f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Loss: 0.05624229907989502\n",
      "Spend time for 300 batches: 102.3834879398346 sec\n",
      "Train Epoch: 1, Loss: 0.009145987232526144\n",
      "Spend time for 300 batches: 103.09858179092407 sec\n",
      "Train Epoch: 1, Loss: 0.011683658560117086\n",
      "Spend time for 300 batches: 103.74246835708618 sec\n",
      "Train Epoch: 1, Loss: 0.006861371596654256\n",
      "Spend time for 300 batches: 103.24788451194763 sec\n",
      "Epoch 1, train loss: 0.02016467460483875\n",
      "Train Epoch: 2, Loss: 0.0072389378150304155\n",
      "Spend time for 300 batches: 102.5597140789032 sec\n",
      "Train Epoch: 2, Loss: 0.006068665981292725\n",
      "Spend time for 300 batches: 102.10100078582764 sec\n",
      "Train Epoch: 2, Loss: 0.006499105493227641\n",
      "Spend time for 300 batches: 101.81708836555481 sec\n",
      "Train Epoch: 2, Loss: 0.005942440629005432\n",
      "Spend time for 300 batches: 102.50844478607178 sec\n",
      "Epoch 2, train loss: 0.006390716435399445\n",
      "Train Epoch: 3, Loss: 0.005424115657806396\n",
      "Spend time for 300 batches: 102.09443306922913 sec\n",
      "Train Epoch: 3, Loss: 0.005184808969497681\n",
      "Spend time for 300 batches: 101.29469299316406 sec\n",
      "Train Epoch: 3, Loss: 0.0080713951587677\n",
      "Spend time for 300 batches: 101.78976392745972 sec\n",
      "Train Epoch: 3, Loss: 0.006122019290924072\n",
      "Spend time for 300 batches: 101.68941378593445 sec\n",
      "Epoch 3, train loss: 0.0061747680107752485\n",
      "Train Epoch: 4, Loss: 0.005210059285163879\n",
      "Spend time for 300 batches: 101.18422389030457 sec\n",
      "Train Epoch: 4, Loss: 0.0051149106025695805\n",
      "Spend time for 300 batches: 101.65098333358765 sec\n",
      "Train Epoch: 4, Loss: 0.005102418661117554\n",
      "Spend time for 300 batches: 101.2301242351532 sec\n",
      "Train Epoch: 4, Loss: 0.005120760401089986\n",
      "Spend time for 300 batches: 101.25072765350342 sec\n",
      "Epoch 4, train loss: 0.005132807406989284\n",
      "Train Epoch: 5, Loss: 0.004766714771588644\n",
      "Spend time for 300 batches: 101.01605534553528 sec\n",
      "Train Epoch: 5, Loss: 0.004647632638613383\n",
      "Spend time for 300 batches: 100.95124697685242 sec\n",
      "Train Epoch: 5, Loss: 0.0047951104243596394\n",
      "Spend time for 300 batches: 101.13328337669373 sec\n",
      "Train Epoch: 5, Loss: 0.004818850954373678\n",
      "Spend time for 300 batches: 101.61301517486572 sec\n",
      "Epoch 5, train loss: 0.005158050208346649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch_train_losses': [0.02016467460483875,\n",
       "  0.006390716435399445,\n",
       "  0.0061747680107752485,\n",
       "  0.005132807406989284,\n",
       "  0.005158050208346649],\n",
       " 'epoch_valid_losses': [None, None, None, None, None],\n",
       " 'epoch_valid_metrics': [None, None, None, None, None]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(criterion,\n",
    "             metric,\n",
    "             optimizer,\n",
    "             train_data_loader,\n",
    "             #valid_data_loader,\n",
    "             epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e2d15ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем веса обученной модели\n",
    "my_model.save(path_to_save = './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9e78f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем оттрассированную модель\n",
    "my_model.trace_save(path_to_save = './model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf700bfa",
   "metadata": {},
   "source": [
    "## Загрузка сохраненной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6a384ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспроизводим модель по известной архитектуре и сохраненным весам\n",
    "model = smp.Unet('mobilenet_v2', classes=1, encoder_depth=5, \n",
    "                 encoder_weights='imagenet', decoder_channels = [256, 128, 64, 32, 16]).to(device)\n",
    "\n",
    "my_model = NeuralNetwork(model=model)\n",
    "my_model.load(path_to_model = './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "9fb8d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем оттрассированную модель\n",
    "my_model = torch.jit.load('./model.pt')\n",
    "my_model = NeuralNetwork(model=my_model)\n",
    "my_model = my_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c988cd6",
   "metadata": {},
   "source": [
    "## Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a31d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_directory = '/home/dima/carvana_dataset/test/predict_small/'\n",
    "test_dataset = '/home/dima/carvana_dataset/test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6cc16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = {}\n",
    "test_dataframe['img_addr'] = list(glob.glob(test_dataset + \"/*\"))\n",
    "test_dataframe = pd.DataFrame(test_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b8aa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CustomDatasetForTest(test_dataframe)\n",
    "test_data_loader = DataLoader(test_data, batch_size=2, shuffle=False)\n",
    "#loader = iter(test_data_loader)\n",
    "#index, img, img_name = loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51507db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rle_dataframe = my_model.predict(test_data_loader, predict_directory, \n",
    "                                 mask_treashold=mask_treashold, generate_rle_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ad9e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем датафрейм с результатом для заливки на kaggle\n",
    "rle_dataframe.to_csv('rle_dataframe.csv', index=True)\n",
    "sample_submission = pd.read_csv('/home/dima/carvana_dataset/sample_submission.csv')\n",
    "sample_submission = sample_submission.merge(rle_dataframe, how='left', left_on='img', right_on='img_name')\n",
    "sample_submission.drop(columns=['rle_mask', 'img_name'], inplace=True)\n",
    "sample_submission.rename(columns={'img_rle': 'rle_mask'}, inplace=True)\n",
    "sample_submission.to_csv('submission_04_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81effd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aef955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 5, train loss: 0.006944334619686383, valid_loss: 0.0050198428332805635, valid_metric: 0.9925926834344864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde352f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
