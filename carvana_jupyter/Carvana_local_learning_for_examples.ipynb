{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2173b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26410a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c147afd",
   "metadata": {},
   "source": [
    "## Метрики с которыми надо поэкспериментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/lyakaap/weighing-boundary-pixels-loss-script-by-keras2\n",
    "\n",
    "# weight: weighted tensor(same shape with mask image)\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "    (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + \\\n",
    "    weighted_dice_loss(y_true, y_pred, weight)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4485f",
   "metadata": {},
   "source": [
    "## Разбор дообучения моделей и заморозки слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "482b2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet('mobilenet_v2', classes=1, encoder_depth=5, \n",
    "                 encoder_weights='imagenet', decoder_channels = [256, 128, 64, 32, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb60ff9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "463ec2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder\n",
      "encoder.features\n",
      "encoder.features.0\n",
      "encoder.features.0.0\n",
      "encoder.features.0.1\n",
      "encoder.features.0.2\n",
      "encoder.features.1\n",
      "encoder.features.1.conv\n",
      "encoder.features.1.conv.0\n",
      "encoder.features.1.conv.0.0\n",
      "encoder.features.1.conv.0.1\n",
      "encoder.features.1.conv.0.2\n",
      "encoder.features.1.conv.1\n",
      "encoder.features.1.conv.2\n",
      "encoder.features.2\n",
      "encoder.features.2.conv\n",
      "encoder.features.2.conv.0\n",
      "encoder.features.2.conv.0.0\n",
      "encoder.features.2.conv.0.1\n",
      "encoder.features.2.conv.0.2\n",
      "encoder.features.2.conv.1\n",
      "encoder.features.2.conv.1.0\n",
      "encoder.features.2.conv.1.1\n",
      "encoder.features.2.conv.1.2\n",
      "encoder.features.2.conv.2\n",
      "encoder.features.2.conv.3\n",
      "encoder.features.3\n",
      "encoder.features.3.conv\n",
      "encoder.features.3.conv.0\n",
      "encoder.features.3.conv.0.0\n",
      "encoder.features.3.conv.0.1\n",
      "encoder.features.3.conv.0.2\n",
      "encoder.features.3.conv.1\n",
      "encoder.features.3.conv.1.0\n",
      "encoder.features.3.conv.1.1\n",
      "encoder.features.3.conv.1.2\n",
      "encoder.features.3.conv.2\n",
      "encoder.features.3.conv.3\n",
      "encoder.features.4\n",
      "encoder.features.4.conv\n",
      "encoder.features.4.conv.0\n",
      "encoder.features.4.conv.0.0\n",
      "encoder.features.4.conv.0.1\n",
      "encoder.features.4.conv.0.2\n",
      "encoder.features.4.conv.1\n",
      "encoder.features.4.conv.1.0\n",
      "encoder.features.4.conv.1.1\n",
      "encoder.features.4.conv.1.2\n",
      "encoder.features.4.conv.2\n",
      "encoder.features.4.conv.3\n",
      "encoder.features.5\n",
      "encoder.features.5.conv\n",
      "encoder.features.5.conv.0\n",
      "encoder.features.5.conv.0.0\n",
      "encoder.features.5.conv.0.1\n",
      "encoder.features.5.conv.0.2\n",
      "encoder.features.5.conv.1\n",
      "encoder.features.5.conv.1.0\n",
      "encoder.features.5.conv.1.1\n",
      "encoder.features.5.conv.1.2\n",
      "encoder.features.5.conv.2\n",
      "encoder.features.5.conv.3\n",
      "encoder.features.6\n",
      "encoder.features.6.conv\n",
      "encoder.features.6.conv.0\n",
      "encoder.features.6.conv.0.0\n",
      "encoder.features.6.conv.0.1\n",
      "encoder.features.6.conv.0.2\n",
      "encoder.features.6.conv.1\n",
      "encoder.features.6.conv.1.0\n",
      "encoder.features.6.conv.1.1\n",
      "encoder.features.6.conv.1.2\n",
      "encoder.features.6.conv.2\n",
      "encoder.features.6.conv.3\n",
      "encoder.features.7\n",
      "encoder.features.7.conv\n",
      "encoder.features.7.conv.0\n",
      "encoder.features.7.conv.0.0\n",
      "encoder.features.7.conv.0.1\n",
      "encoder.features.7.conv.0.2\n",
      "encoder.features.7.conv.1\n",
      "encoder.features.7.conv.1.0\n",
      "encoder.features.7.conv.1.1\n",
      "encoder.features.7.conv.1.2\n",
      "encoder.features.7.conv.2\n",
      "encoder.features.7.conv.3\n",
      "encoder.features.8\n",
      "encoder.features.8.conv\n",
      "encoder.features.8.conv.0\n",
      "encoder.features.8.conv.0.0\n",
      "encoder.features.8.conv.0.1\n",
      "encoder.features.8.conv.0.2\n",
      "encoder.features.8.conv.1\n",
      "encoder.features.8.conv.1.0\n",
      "encoder.features.8.conv.1.1\n",
      "encoder.features.8.conv.1.2\n",
      "encoder.features.8.conv.2\n",
      "encoder.features.8.conv.3\n",
      "encoder.features.9\n",
      "encoder.features.9.conv\n",
      "encoder.features.9.conv.0\n",
      "encoder.features.9.conv.0.0\n",
      "encoder.features.9.conv.0.1\n",
      "encoder.features.9.conv.0.2\n",
      "encoder.features.9.conv.1\n",
      "encoder.features.9.conv.1.0\n",
      "encoder.features.9.conv.1.1\n",
      "encoder.features.9.conv.1.2\n",
      "encoder.features.9.conv.2\n",
      "encoder.features.9.conv.3\n",
      "encoder.features.10\n",
      "encoder.features.10.conv\n",
      "encoder.features.10.conv.0\n",
      "encoder.features.10.conv.0.0\n",
      "encoder.features.10.conv.0.1\n",
      "encoder.features.10.conv.0.2\n",
      "encoder.features.10.conv.1\n",
      "encoder.features.10.conv.1.0\n",
      "encoder.features.10.conv.1.1\n",
      "encoder.features.10.conv.1.2\n",
      "encoder.features.10.conv.2\n",
      "encoder.features.10.conv.3\n",
      "encoder.features.11\n",
      "encoder.features.11.conv\n",
      "encoder.features.11.conv.0\n",
      "encoder.features.11.conv.0.0\n",
      "encoder.features.11.conv.0.1\n",
      "encoder.features.11.conv.0.2\n",
      "encoder.features.11.conv.1\n",
      "encoder.features.11.conv.1.0\n",
      "encoder.features.11.conv.1.1\n",
      "encoder.features.11.conv.1.2\n",
      "encoder.features.11.conv.2\n",
      "encoder.features.11.conv.3\n",
      "encoder.features.12\n",
      "encoder.features.12.conv\n",
      "encoder.features.12.conv.0\n",
      "encoder.features.12.conv.0.0\n",
      "encoder.features.12.conv.0.1\n",
      "encoder.features.12.conv.0.2\n",
      "encoder.features.12.conv.1\n",
      "encoder.features.12.conv.1.0\n",
      "encoder.features.12.conv.1.1\n",
      "encoder.features.12.conv.1.2\n",
      "encoder.features.12.conv.2\n",
      "encoder.features.12.conv.3\n",
      "encoder.features.13\n",
      "encoder.features.13.conv\n",
      "encoder.features.13.conv.0\n",
      "encoder.features.13.conv.0.0\n",
      "encoder.features.13.conv.0.1\n",
      "encoder.features.13.conv.0.2\n",
      "encoder.features.13.conv.1\n",
      "encoder.features.13.conv.1.0\n",
      "encoder.features.13.conv.1.1\n",
      "encoder.features.13.conv.1.2\n",
      "encoder.features.13.conv.2\n",
      "encoder.features.13.conv.3\n",
      "encoder.features.14\n",
      "encoder.features.14.conv\n",
      "encoder.features.14.conv.0\n",
      "encoder.features.14.conv.0.0\n",
      "encoder.features.14.conv.0.1\n",
      "encoder.features.14.conv.0.2\n",
      "encoder.features.14.conv.1\n",
      "encoder.features.14.conv.1.0\n",
      "encoder.features.14.conv.1.1\n",
      "encoder.features.14.conv.1.2\n",
      "encoder.features.14.conv.2\n",
      "encoder.features.14.conv.3\n",
      "encoder.features.15\n",
      "encoder.features.15.conv\n",
      "encoder.features.15.conv.0\n",
      "encoder.features.15.conv.0.0\n",
      "encoder.features.15.conv.0.1\n",
      "encoder.features.15.conv.0.2\n",
      "encoder.features.15.conv.1\n",
      "encoder.features.15.conv.1.0\n",
      "encoder.features.15.conv.1.1\n",
      "encoder.features.15.conv.1.2\n",
      "encoder.features.15.conv.2\n",
      "encoder.features.15.conv.3\n",
      "encoder.features.16\n",
      "encoder.features.16.conv\n",
      "encoder.features.16.conv.0\n",
      "encoder.features.16.conv.0.0\n",
      "encoder.features.16.conv.0.1\n",
      "encoder.features.16.conv.0.2\n",
      "encoder.features.16.conv.1\n",
      "encoder.features.16.conv.1.0\n",
      "encoder.features.16.conv.1.1\n",
      "encoder.features.16.conv.1.2\n",
      "encoder.features.16.conv.2\n",
      "encoder.features.16.conv.3\n",
      "encoder.features.17\n",
      "encoder.features.17.conv\n",
      "encoder.features.17.conv.0\n",
      "encoder.features.17.conv.0.0\n",
      "encoder.features.17.conv.0.1\n",
      "encoder.features.17.conv.0.2\n",
      "encoder.features.17.conv.1\n",
      "encoder.features.17.conv.1.0\n",
      "encoder.features.17.conv.1.1\n",
      "encoder.features.17.conv.1.2\n",
      "encoder.features.17.conv.2\n",
      "encoder.features.17.conv.3\n",
      "encoder.features.18\n",
      "encoder.features.18.0\n",
      "encoder.features.18.1\n",
      "encoder.features.18.2\n",
      "decoder\n",
      "decoder.center\n",
      "decoder.blocks\n",
      "decoder.blocks.0\n",
      "decoder.blocks.0.conv1\n",
      "decoder.blocks.0.conv1.0\n",
      "decoder.blocks.0.conv1.1\n",
      "decoder.blocks.0.conv1.2\n",
      "decoder.blocks.0.attention1\n",
      "decoder.blocks.0.attention1.attention\n",
      "decoder.blocks.0.conv2\n",
      "decoder.blocks.0.conv2.0\n",
      "decoder.blocks.0.conv2.1\n",
      "decoder.blocks.0.conv2.2\n",
      "decoder.blocks.0.attention2\n",
      "decoder.blocks.0.attention2.attention\n",
      "decoder.blocks.1\n",
      "decoder.blocks.1.conv1\n",
      "decoder.blocks.1.conv1.0\n",
      "decoder.blocks.1.conv1.1\n",
      "decoder.blocks.1.conv1.2\n",
      "decoder.blocks.1.attention1\n",
      "decoder.blocks.1.attention1.attention\n",
      "decoder.blocks.1.conv2\n",
      "decoder.blocks.1.conv2.0\n",
      "decoder.blocks.1.conv2.1\n",
      "decoder.blocks.1.conv2.2\n",
      "decoder.blocks.1.attention2\n",
      "decoder.blocks.1.attention2.attention\n",
      "decoder.blocks.2\n",
      "decoder.blocks.2.conv1\n",
      "decoder.blocks.2.conv1.0\n",
      "decoder.blocks.2.conv1.1\n",
      "decoder.blocks.2.conv1.2\n",
      "decoder.blocks.2.attention1\n",
      "decoder.blocks.2.attention1.attention\n",
      "decoder.blocks.2.conv2\n",
      "decoder.blocks.2.conv2.0\n",
      "decoder.blocks.2.conv2.1\n",
      "decoder.blocks.2.conv2.2\n",
      "decoder.blocks.2.attention2\n",
      "decoder.blocks.2.attention2.attention\n",
      "decoder.blocks.3\n",
      "decoder.blocks.3.conv1\n",
      "decoder.blocks.3.conv1.0\n",
      "decoder.blocks.3.conv1.1\n",
      "decoder.blocks.3.conv1.2\n",
      "decoder.blocks.3.attention1\n",
      "decoder.blocks.3.attention1.attention\n",
      "decoder.blocks.3.conv2\n",
      "decoder.blocks.3.conv2.0\n",
      "decoder.blocks.3.conv2.1\n",
      "decoder.blocks.3.conv2.2\n",
      "decoder.blocks.3.attention2\n",
      "decoder.blocks.3.attention2.attention\n",
      "decoder.blocks.4\n",
      "decoder.blocks.4.conv1\n",
      "decoder.blocks.4.conv1.0\n",
      "decoder.blocks.4.conv1.1\n",
      "decoder.blocks.4.conv1.2\n",
      "decoder.blocks.4.attention1\n",
      "decoder.blocks.4.attention1.attention\n",
      "decoder.blocks.4.conv2\n",
      "decoder.blocks.4.conv2.0\n",
      "decoder.blocks.4.conv2.1\n",
      "decoder.blocks.4.conv2.2\n",
      "decoder.blocks.4.attention2\n",
      "decoder.blocks.4.attention2.attention\n",
      "segmentation_head\n",
      "segmentation_head.0\n",
      "segmentation_head.1\n",
      "segmentation_head.2\n",
      "segmentation_head.2.activation\n"
     ]
    }
   ],
   "source": [
    "for (name, module) in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50b14911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ConvBNActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): ConvBNActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (18): ConvBNActivation(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for (name, module) in model.named_children():\n",
    "    if name == 'encoder':\n",
    "        for layer in module.children():\n",
    "            print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e76a703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer \"0\" in module \"encoder\" was frozen!\n"
     ]
    }
   ],
   "source": [
    "layer_counter = 0\n",
    "for (name, module) in model.named_children():\n",
    "    if name == 'encoder':\n",
    "        for layer in module.children():\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            print('Layer \"{}\" in module \"{}\" was frozen!'.format(layer_counter, name))\n",
    "            layer_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, vgg16.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76204ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " for k,v in model.named_parameters():\n",
    "     if k.startswith('conv1') or k.startswith('layer1'):\n",
    "         v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37cf537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d638dcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9992/117025980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1105\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/segmentation_models_pytorch/encoders/mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1105\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1105\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e3c9",
   "metadata": {},
   "source": [
    "## Сравнение скорости работы OpenCV и PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1fe0f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/home/dima/carvana_dataset/train/train'\n",
    "dst_dir = '/home/dima/carvana_dataset/train/train_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d36353cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_get_image_rw_time(src_dir: str, dst_dir: str, max_img: int=100):\n",
    "    \n",
    "    train_files = os.listdir(src_dir)\n",
    "    random.shuffle(train_files)\n",
    "\n",
    "    for i, f in tqdm.tqdm(enumerate(train_files)):\n",
    "        img_pil = Image.open(os.path.join(src_dir, f))\n",
    "        img_pil = np.array(img_pil)\n",
    "        img_pil = Image.fromarray(np.uint8(img_pil)).convert('RGB')\n",
    "        img_pil.save(os.path.join(dst_dir, f))\n",
    "        #print(type(img_pil))\n",
    "        if i >= max_img:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "02b44522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_2_get_image_rw_time(src_dir: str, dst_dir: str, max_img: int=100):\n",
    "    \n",
    "    train_files = os.listdir(src_dir)\n",
    "    random.shuffle(train_files)\n",
    "\n",
    "    for i, f in tqdm.tqdm(enumerate(train_files)):\n",
    "        img_cv2 = cv2.imread(os.path.join(src_dir, f))\n",
    "        cv2.imwrite(os.path.join(dst_dir, f), img_cv2)\n",
    "        if i >= max_img:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd427121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:05, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.86529278755188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!rm /home/dima/carvana_dataset/train/train_small/*\n",
    "time1 = time.time()\n",
    "pil_get_image_rw_time(src_dir, dst_dir, max_img=100)\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3dd91bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:03, 25.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8542134761810303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!rm /home/dima/carvana_dataset/train/train_small/*\n",
    "time1 = time.time()\n",
    "cv_2_get_image_rw_time(src_dir, dst_dir, max_img=100)\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01656094",
   "metadata": {},
   "source": [
    "## Определение среднего и дисперсии набора изображений по каналам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce37158",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/home/dima/carvana_dataset/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1f7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_image(src_dir: str, max_img: int=100):\n",
    "    img_mean_sum = np.zeros(3, np.float64)\n",
    "    img_var_sum = np.zeros(3, np.float64)\n",
    "\n",
    "    train_files = os.listdir(src_dir)\n",
    "    random.shuffle(train_files)\n",
    "\n",
    "    for i, f in tqdm.tqdm(enumerate(train_files)):\n",
    "        image = cv2.imread(os.path.join(src_dir, f))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype('float')/255.0\n",
    "        channels = image.reshape((-1, 3))\n",
    "        img_mean_sum += channels.mean(axis=0)\n",
    "        img_var_sum += channels.var(axis=0)\n",
    "        if i >= max_img:\n",
    "            break\n",
    "\n",
    "    chan_mean = img_mean_sum / (i + 1)\n",
    "    chan_std = (img_var_sum / (i + 1)) ** 0.5\n",
    "\n",
    "    print('channels mean:', chan_mean)\n",
    "    print('channels std:', chan_std)\n",
    "    #np.save(CHANNELS_MEAN, chan_mean)\n",
    "    #np.save(CHANNELS_STD, chan_std)\n",
    "    return chan_mean, chan_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52564762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:16,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels mean: [0.69606284 0.68972409 0.68443157]\n",
      "channels std: [0.23977361 0.24345116 0.24009687]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chan_mean, chan_std = calculate_mean_image(src_dir, max_img=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2480cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function preprocess_input at 0x7fcbc0b0c550>, input_space='RGB', input_range=[0, 1], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Среднее и дисперсия для imagenet\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "preprocess_input = get_preprocessing_fn('mobilenet_v2', pretrained='imagenet')\n",
    "preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf2e4a",
   "metadata": {},
   "source": [
    "## Преобразование масок из gif в jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "422b3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e017dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/home/dima/carvana_dataset/train_masks/train_masks'\n",
    "dst_dir = '/home/dima/carvana_dataset/train_masks/train_masks_jpg'\n",
    "\n",
    "def gif_to_jpg(src_dir: str, src_dst: str):\n",
    "    train_files = os.listdir(src_dir)\n",
    "    for i, f in tqdm.tqdm(enumerate(train_files)):\n",
    "        mask = Image.open(os.path.join(src_dir, f))  \n",
    "        mask.save(os.path.join(dst_dir, f).split('.')[0] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8219553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5088it [00:46, 108.42it/s]\n"
     ]
    }
   ],
   "source": [
    "gif_to_jpg(src_dir, src_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb6fd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/home/dima/carvana_dataset/train_masks/train_masks_png/4fc2470c0f7b_13_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aee1d7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 255], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "176f472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1918, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231177c",
   "metadata": {},
   "source": [
    "## Работа с ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bb6b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import torch\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c839f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt install nvidia-cuda-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf922c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct  7 16:13:17 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 37%   62C    P2   104W / 170W |  11450MiB / 12045MiB |     41%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       958      G   /usr/lib/xorg/Xorg                 35MiB |\r\n",
      "|    0   N/A  N/A      1653      G   /usr/lib/xorg/Xorg                140MiB |\r\n",
      "|    0   N/A  N/A      1783      G   /usr/bin/gnome-shell               48MiB |\r\n",
      "|    0   N/A  N/A     15067      G   /usr/lib/firefox/firefox          138MiB |\r\n",
      "|    0   N/A  N/A     15188      G   /usr/lib/firefox/firefox            2MiB |\r\n",
      "|    0   N/A  N/A     15191      G   /usr/lib/firefox/firefox            2MiB |\r\n",
      "|    0   N/A  N/A     15198      G   /usr/lib/firefox/firefox            2MiB |\r\n",
      "|    0   N/A  N/A     15219      G   /usr/lib/firefox/firefox            2MiB |\r\n",
      "|    0   N/A  N/A     16939      C   ...dima/anaconda3/bin/python    11063MiB |\r\n",
      "|    0   N/A  N/A     16984      G   /usr/bin/nvidia-settings            0MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50dd998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407ba9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbb2bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxruntime.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e68fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f7258aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8005"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4624afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cuda.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4ee354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONNX_model(object):\n",
    "    def __init__(self, model_addr: str):\n",
    "        super(ONNX_model, self).__init__()\n",
    "        self.model_addr = model_addr\n",
    "    \n",
    "    def run_session(self):\n",
    "        ort_session = onnxruntime.InferenceSession(self.model_addr)\n",
    "        input_name = ort_session.get_inputs()[0].name\n",
    "    \n",
    "    def check(self):\n",
    "        onnx_model = onnx.load(self.model_addr)\n",
    "        print(onnx.checker.check_model(onnx_model))\n",
    "    \n",
    "    def predict(self):\n",
    "        ort_inputs = {input_name: np.random.randn(2, 3, 512, 512).astype(np.float32)}\n",
    "        return ort_session.run(None, ort_inputs)\n",
    "\n",
    "a = ONNX_model('./carvana_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a80c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession('./carvana_model.onnx')\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "ort_inputs = {input_name: np.random.randn(2, 3, 1024, 1024).astype(np.float32)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59c7fc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 1024, 1024)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3890f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetForONNX(Dataset):\n",
    "    '''Класс для создания тестовых датасетов'''\n",
    "    def __init__(self, data_info, transform: object):\n",
    "        '''Входные параметры:\n",
    "        data_info: pd.DataFrame - датафрейм с адресами и именами изображений\n",
    "        transform: object - список трансформации, которым будут подвергнуты изображения\n",
    "        Возвращаемые значения:\n",
    "        объект класса CustomDatasetForTest'''\n",
    "        # Подаем наш подготовленный датафрейм\n",
    "        self.data_info = data_info\n",
    "        # Получаем адреса RGB изображений \n",
    "        self.image_addresses = self.data_info.iloc[:,0]\n",
    "        # Получаем имена RGB изображений \n",
    "        self.image_names = self.data_info.iloc[:,1]\n",
    "        # Количество пар картинка-сегментация\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        # Сохраняем преобразования данных\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Входные параметры:\n",
    "        img: int - индекс для обращения к элементам датафрейма data_info\n",
    "        Возвращаемые значения:\n",
    "        img: torch.Tensor - тензорное представление изображения с размерностью out_shape\n",
    "        mask_small: torch.Tensor - тензорное представление маски с исходной размерностью\n",
    "        image_name: str - имя изображения'''\n",
    "        image = cv2.imread(self.image_addresses[index])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype('float')/255.0\n",
    "        \n",
    "        transformed = self.transform(image=image)\n",
    "        tr_image = transformed['image']\n",
    "        image_name = self.image_names[index]\n",
    "    \n",
    "        return (index, tr_image, image_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db210256",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_directory = '/home/dima/carvana_dataset/test/predict_small/'\n",
    "test_dataset = '/home/dima/carvana_dataset/test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "222e54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = {}\n",
    "test_dataframe['img_addr'] = list(glob.glob(test_dataset + \"/*\"))\n",
    "test_dataframe = pd.DataFrame(test_dataframe)\n",
    "test_dataframe['img_name'] = test_dataframe['img_addr'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd877868",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transform = A.Compose([\n",
    "    A.Resize(1024, 1024, cv2.INTER_LINEAR),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d216c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CustomDatasetForONNX(test_dataframe, valid_transform)\n",
    "test_data_loader = DataLoader(test_data, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8195b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = iter(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e44431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = aa.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "879896c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be5a0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57ab2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 1024, 1024)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "509471c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f0e0de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4494a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_rle(tensor: torch.Tensor) -> str:\n",
    "    with torch.no_grad():\n",
    "        tensor = tensor.view(1, -1)\n",
    "        tensor = tensor.squeeze(0)\n",
    "        tensor[0] = 0\n",
    "        tensor[-1] = 0\n",
    "        rle = torch.where(tensor[1:] != tensor[:-1])[0] + 2\n",
    "        rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "        rle = rle.cpu().detach().numpy()\n",
    "        rle_str = rle_to_string(rle)\n",
    "        return rle_str\n",
    "    \n",
    "def rle_to_string(runs: torch.Tensor) -> str:\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "422fe3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Processed images: 600\n",
      "Total time: 299.56 sec\n",
      "Time to process 600 images: 299.56 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15815/1363748231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mort_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mort_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpred_mask_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_names = []\n",
    "img_rles = []\n",
    "time1 = time.time()\n",
    "time2 = time.time()\n",
    "mask_treashold = 0.5\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('./carvana_model.onnx')\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "for batch_idx, (index, img, img_name)  in enumerate(test_data_loader):\n",
    "\n",
    "    img = img.numpy()\n",
    "    ort_inputs = {input_name: img.astype(np.float32)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    pred_mask_logit = torch.from_numpy(ort_outs[0])\n",
    "    \n",
    "    pred_mask_logit = F.interpolate(input=pred_mask_logit, size=(1280, 1918), mode='nearest')\n",
    "    pred_mask_logit_prob = torch.sigmoid(pred_mask_logit)\n",
    "    pred_mask = torch.where(pred_mask_logit_prob > mask_treashold, 1, 0)\n",
    "            \n",
    "    # Каждое изображение в тензоре преобразуем в картинку и сохраняем\n",
    "    for i in range(pred_mask.shape[0]):\n",
    "        #if predict_directory != None:\n",
    "        #    mask = (pred_mask[i].cpu().numpy() * 255.0)[0] # [0] - избавляемся от батч размерности\n",
    "        #    PIL_image = Image.fromarray(mask.astype('uint8'), 'L')\n",
    "        #    PIL_image.save((predict_directory+img_name[i]).split('.')[0]+'.gif')\n",
    "                \n",
    "        # Если требуется, получаем значения rle для каждой картинки\n",
    "\n",
    "        img_names.append(img_name[i])\n",
    "        img_rles.append(tensor_to_rle(pred_mask[i]))\n",
    "            \n",
    "    if (batch_idx+1) % 300 == 0:\n",
    "            print('-'*50)\n",
    "            print(f'Processed images: {(batch_idx+1)*img.shape[0]}')\n",
    "            time3 = time.time()\n",
    "            print(f'Total time: {(time3-time1):.2f} sec')\n",
    "            print(f'Time to process {300*img.shape[0]} images: {(time3-time2):.2f} sec')\n",
    "            time2 = time.time()\n",
    "                \n",
    "\n",
    "rle_dataframe = pd.DataFrame(list(zip(img_names, img_rles)), columns =['img_name', 'img_rle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be1eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
